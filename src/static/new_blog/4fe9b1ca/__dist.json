{"articles": {"2021-12-31/-shi-yong-RPC-gou-jian-gao-bing-fa-web-ying-yong": {"title": "使用RPC构建高并发web应用", "category": "web", "description": "", "date": "2021-12-31", "ref": "", "author": "", "tags": ["protobuf", "web", "rpc"], "identity": "2021-12-31/-shi-yong-RPC-gou-jian-gao-bing-fa-web-ying-yong", "content": "## 使用RPC构建高并发web应用\n\n> 声明：部分插图来源于互联网\n\n#### 目录：\n1. RPC概述\n2. Redis文本协议\n3. Protobuf协议\n4. gRPC实践\n\n### 1. 什么是 RPC ？\nRPC (Remote Procedure Call)即远程过程调用。除 RPC 之外，常见的多系统数据交互方案还有分布式消息队列、HTTP 请求调用、数据库和分布式缓存等。\n\nRPC 是两个子系统之间进行的直接消息交互，它使用操作系统提供的套接字来作为消息的载体，以特定的消息格式来定义消息内容和边界。\n\n![](/static/new_blog/4fe9b1ca/2021-12-31/img/rpc.jpg)\n\n现代企业的关键性 RPC 服务是绝不可以只使用单点部署的。对 RPC 服务进行分布式化，使得服务可以容忍个别节点故障仍能继续对外提供服务。\n\n![](/static/new_blog/4fe9b1ca/2021-12-31/img/cs.jpg)\n\n#### * 容灾 Failover与降权\n比如当节点挂掉时，将失效节点摘除，放置到失效节点列表中。然后每隔一段时间检查失效节点是否恢复了，如果恢复了，那就从失效节点中移除，再将节点地址重新加入到有效节点列表中：\n1. 常用时间窗口降权法，统计在一定时间窗口里出现的错误数量，过大则降权\n2. 不降到零，那是为了给节点提供一个恢复的机会。\n3. 被降权的节点后来只要有一次调用成功，那么 weight 值就应该尽快被还原\n\n一个简单的策略是权重减半法。错误一次权重减半，连续错误两次权重就降到 1/4，如此直到降到最小值。如果初始权重值是 1024，那么权重值就会逐渐衰减```1024=>512=>256=>128=>64=>32=>16=>8=>4=>2=>1```。\n如果节点恢复了，那么调用会成功，权重就可以直接恢复到正常值，也可以通过加倍法逐渐恢复到正常值```1=>2=>4=>8=>16=>32=>64=>128=>256=>512=>1024```。\n如果希望恢复的更快一点，可以通过乘 4 法，乘 8 法。\n\n#### * 服务发现\n健壮的服务应该是可以支持动态扩容的服务。当 RPC 服务节点增加或减少时，客户端可以动态快速收到服务列表的变更信息，从而可以实时调整连接配置，这样无需重启就可以完成服务的扩容和缩容。\n\n![](/static/new_blog/4fe9b1ca/2021-12-31/img/dynamic_deploy.png)\n\n服务发现技术依赖于服务之间的特殊中间节点。这个节点的作用就是接受服务的注册，提供服务的查找，以及服务列表变更的实时通知功能。它一般使用支持高可用的分布式配置数据库作为解决方案，如 zookeeper/etcd 等。\n\n- 服务注册——服务节点在启动时将自己的服务地址注册到中间节点\n- 服务查找——客户端启动时去中间节点查询服务地址列表\n- 服务变更通知——客户端在中间节点上订阅依赖服务列表的变更事件。当依赖的服务列表变更时，中间节点负责将变更信息实时通知给客户端。\n\n![](/static/new_blog/4fe9b1ca/2021-12-31/img/service_reg.png)\n\n### 2. Redis文本协议 RESP (Redis Serialization Protocol)\n\n对于一串消息流，我们必须能确定消息边界，提取出单条消息的字节流片段，然后对这个片段按照一定的规则进行反序列化来生成相应的消息对象。\n![](/static/new_blog/4fe9b1ca/2021-12-31/img/msg.png)\n\nRESP 是 Redis 序列化协议的简写。它是一种直观的文本协议，优势在于实现异常简单，解析性能极好。\n\nRedis 协议将传输的结构数据分为 5 种最小单元类型，单元结束时统一加上回车换行符号\\r\\n。\n\n1. 单行字符串 以+符号开头；\n2. 多行字符串 以$符号开头，后跟字符串长度；\n3. 整数值 以:符号开头，后跟整数的字符串形式；\n4. 错误消息 以-符号开头；\n5. 数组 以*号开头，后跟数组的长度；\n\n单行字符串 hello world\n```\n+hello world\\r\\n\n```\n直观打印如下：\n```\n+hello world\n```\n多行字符串 第一行是长度，剩下的是内容，表示字符串 hello world 如下：\n\n```\n$11\\r\\nhello world\\r\\n\n```\n直观打印如下：\n```\n$11\nhello world\n```\n多行字符串当然也可以表示单行字符串。\n\n整数 冒号开头 表示整数 1024 如下：\n```\n:1024\\r\\n\n```\n直观打印如下：\n```\n:1024\n```\n错误 减号开头后跟错误名称和详细错误解释 表示「参数类型错误」如下：\n```\n-WRONGTYPE Operation against a key holding the wrong kind of value\\r\\n\n```\n直观打印如下：\n```\n-WRONGTYPE Operation against a key holding the wrong kind of value\n```\n数组 第一行是长度，后面依次是每个内容，表示数组 [1,2,3] 如下：\n```\n*3\\r\\n:1\\r\\n:2\\r\\n:3\\r\\n\n```\n直观打印如下：\n```\n*3\n:1\n:2\n:3\n```\n数组里面可以嵌套其它类型，甚至可以嵌套另外一个数组，如此就可以形成复杂的数据结构。\n\nNULL 用多行字符串表示，不过长度要写成-1。\n```\n$-1\\r\\n\n```\n直观打印如下：\n```\n$-1\n```\n空串 用多行字符串表示，长度填 0。\n```\n$0\\r\\n\\r\\n\n```\n直观打印如下：\n```\n$0\n\n```\n注意这里有两个\\r\\n，为什么是两个，因为两个\\r\\n 之间隔的是空串。\n\n#### 发送指令：客户端 -> 服务器\n\n客户端向服务器发送的指令只有一种格式，多行字符串数组。比如一个简单的 set 指令set author codehole会被序列化成下面的字符串。\n```\n*3\\r\\n$3\\r\\nset\\r\\n$6\\r\\nauthor\\r\\n$8\\r\\ncodehole\\r\\n\n```\n在控制台输出这个字符串如下，可以看出这是很好阅读的一种格式。\n```\n*3\n$3\nset\n$6\nauthor\n$8\ncodehole\n```\n#### 发送指令：服务器 -> 客户端\n服务器向客户端回复的响应要支持多种数据结构，所以消息响应在结构上要复杂不少。不过再复杂的响应消息也是以上 5 中基本类型的组合。\n\n数组响应\n```\n127.0.0.1:6379> hgetall info\n1) \"name\"\n2) \"laoqian\"\n3) \"age\"\n4) \"30\"\n5) \"sex\"\n6) \"male\"\n```\n这里的 hgetall 命令返回的就是一个数值，第 0|2|4 位置的字符串是 hash 表的 key，第 1|3|5 位置的字符串是 value，客户端负责将数组组装成字典再返回。\n```\n*6\n$4\nname\n$6\nlaoqian\n$3\nage\n$2\n30\n$3\nsex\n$4\nmale\n```\n嵌套\n```\n127.0.0.1:6379> scan 0\n1) \"0\"\n2) 1) \"info\"\n   2) \"books\"\n   3) \"author\"\n```\nscan 命令用来扫描服务器包含的所有 key 列表，它是以游标的形式获取，一次只获取一部分。\n\nscan 命令返回的是一个嵌套数组。数组的第一个值表示游标的值，如果这个值为零，说明已经遍历完毕。如果不为零，使用这个值作为 scan 命令的参数进行下一次遍历。数组的第二个值又是一个数组，这个数组就是 key 列表。\n```\n*2\n$1\n0\n*3\n$4\ninfo\n$5\nbooks\n$6\nauthor\n```\n#### 小结\nRedis的协议RESP\n\n1. 消息边界-特殊字符标记法\n2. 消息表示-文本\n3. 消息结构-显示文本自说明\n4. 压缩算法-没用\n\n因为Antirez认为数据库系统的瓶颈不在于网络流量，而在于数据库内部的处理逻辑上。所以，RESP的设计理念是简单、易于理解和使用，消息传输上浪费一些流量并无大碍。\n\n### 3.Protobuf协议\n#### (1) zigzag编码\nzigzag 编码将整数范围一一映射到自然数范围，然后再进行 varint 编码。\n```\n0 => 0\n-1 => 1\n1 => 2\n-2 => 3\n2 => 4\n-3 => 5\n3 => 6\n```\nzigzag 将负数编码成正奇数，正数编码成偶数。解码的时候遇到偶数直接除 2 就是原值，遇到奇数就加 1 除 2 再取负就是原值。\n\n#### (2) varint变长整数编码\n\n保留每个字节的最高位的 bit 来标识是否后面还有字节，1 表示还有字节需要继续读，0 表示到读到当前字节就结束。\n![](/static/new_blog/4fe9b1ca/2021-12-31/img/varint.png)\n数值非常小时，只需要使用一个字节来存储，数值稍微大一点可以使用 2 个字节，再大一点就是 3 个字节，它还可以超过 4 个字节用来表达长整形数字。\n\n#### (3) protobuf\n\n![](/static/new_blog/4fe9b1ca/2021-12-31/img/kv.png)\nProtobuf 传输的是一系列的键值对，如果连续的键重复了，那说明传输的值是一个列表 (repeated)。图上的 key3 就是一个列表类型 (repeated)。\n\n键 key 两部分组成：tag 和 type。\n\n- tag\n\n  Protobuf 将对象中的每个字段和正数序列 (tag) 对应起来\n\n- type\n\n  Protobuf 将字段类型也和正数序列 (type) 对应起来，每一种原生的 java 类型都唯一对应一个正数，类型信息也非常节省。type 使用 3 个 bits 表示，最多支持 8 种类型。\n\n8 种类型够吗？够！因为一个 zigzag 类型可以表示所有的类整数类型，__byte/short/int/long/bool/enum/unsigned byte/unsigned short/unsigned int/unsigned long__ 这些类型都可以使用 zigzag 表示。而 Python 语言的整数更加特别，它根本就不区分整数的位数，甚至可以是一个 BigInteger。varint 的特长就在于此，它可以无限扩展位数大小，可以表示无限的整数值。而字节数组、字符串和嵌套对象都可以使用一种称之为 length 前缀 (length-delimited) 的类型来表示。另外 float 和 double 类型各占一个类型。最终你看，连 8 个类型都没有使用到。\n\n#### key = tag + type\n\nProtobuf 将字段名称对应的整数 (tag) 和字段类型对应的整数 (type) 合并在一起凑成一个字节。如果字段不够，则可以无限扩展。理论上，它支持无数个字段。\n\n下面我们看 value 部分，value 部分随着类型 type 的不同而具有不同的形式\n\n- 整数\n- 浮点数：浮点数分为 float 和 double，它们分别使用 4 个字节和 8 个字节序列化，这两个类型的 value 没有做什么特殊处理，它就是标准的浮点数\n- 字符串：长度前缀编码。第一个varint 编码的值是字符串的长度，后面相应长度的字节串就是字符串的内容\n- 嵌套： type 同字符串的 type 一样，都是 length 前缀。第一个字节varint 编码的值为字节长度，后面相应长度的字节串就是嵌套对象的整个内容，这部分内容会递归使用 Protobuf 进行编码解码\n\n```\nProtobuf ->\n\nmessage Person {\n    required string user_name        = 1;  // 必须字段\n    optional int64  favourite_number = 2;  // 可选字段\n    repeated string interests        = 3;  // 列表类型\n}\n-----------------------\njs ->\n\nvar person = new Person{\n    user_name: \"Martin\",\n    favourite_number: 1337,\n    interests: [\"daydreaming\", \"hacking\"]\n}\n\n```\n![](/static/new_blog/4fe9b1ca/2021-12-31/img/proto_eg.png)\n\n### 4. gRPC实践\n![](/static/new_blog/4fe9b1ca/2021-12-31/img/proto_struct.png)\n\n接下来我们使用 GRPC 来实现一下圆周率计算服务。整个过程分为五步\n\n1. 编写协议文件 pi.proto\n2. 使用grpc_tools工具将 pi.proto编译成pi_pb2.py和pi_pb2_grpc.py两个文件\n3. 使用pi_pb2_grpc.py文件中的服务器接口类，编写服务器具体逻辑实现\n4. 使用pi_pb2_grpc.py文件中的客户端 Stub，编写客户端交互代码\n\n首先我们安装一下工具依赖\n```\npip install grpcio_tools  # tools 包含代码生成工具，会自动安装依赖的 grpcio 包\n```\n编写协议文件 pi.proto\n```\nsyntax = \"proto3\";\n\npackage pi;\n\n// pi service\nservice PiCalculator {\n    // pi method\n    rpc Calc(PiRequest) returns (PiResponse) {}\n}\n\n// pi input\nmessage PiRequest {\n    int32 n = 1;\n}\n\n// pi output\nmessage PiResponse {\n    double value = 1;\n}\n```\n协议文件包含输入消息PiRequest、输出消息PiResponse和 rpc 服务调用的定义PiCalculator\n\n生成代码\n```\npython -m grpc_tools.protoc -I. --python_out=. --grpc_python_out=. pi.proto\n```\n这个命令行有很多参数，其中python_out目录指定pi_pb2.py文件的输出路径，grpc_python_out指定pi_pb2_grpc.py文件的输出路径。-I参数指定协议文件的查找目录，我们都将它们设置为当前目录。\n\nServer:\n```python\n# coding: utf-8\n# server.py\nimport math\nimport grpc\nimport time\nfrom concurrent import futures\n\nimport pi_pb2\nimport pi_pb2_grpc\n\n\n# 圆周率计算服务实现类\nclass PiCalculatorServicer(pi_pb2_grpc.PiCalculatorServicer):\n    def Calc(self, request, ctx):\n        # 计算圆周率的逻辑在这里\n        s = 0.0\n        for i in range(request.n):\n            s += 1.0/(2*i+1)/(2*i+1)\n        # 注意返回的是一个响应对象\n        return pi_pb2.PiResponse(value=math.sqrt(8*s))\n\n\ndef main():\n    # 多线程服务器\n    server = grpc.server(futures.ThreadPoolExecutor(max_workers=10))\n    # 实例化圆周率服务类\n    servicer = PiCalculatorServicer()\n    # 注册本地服务\n    pi_pb2_grpc.add_PiCalculatorServicer_to_server(servicer, server)\n    # 监听端口\n    server.add_insecure_port('127.0.0.1:8080')\n    # 开始接收请求进行服务\n    server.start()\n    # 使用 ctrl+c 可以退出服务\n    try:\n        time.sleep(1000)\n    except KeyboardInterrupt:\n        server.stop(0)\n\n\nif __name__ == '__main__':\n    main()\n```\nClient：\n```python\n# coding: utf-8\n# client.py\n\nimport grpc\n\nimport pi_pb2\nimport pi_pb2_grpc\n\n\ndef main():\n    channel = grpc.insecure_channel('localhost:8080')\n    # 使用 stub\n    client = pi_pb2_grpc.PiCalculatorStub(channel)\n    # 调用吧\n    for i in range(1, 1000):\n        print \"pi(%d) =\" % i, client.Calc(pi_pb2.PiRequest(n=i)).value\n\n\nif __name__ == '__main__':\n    main()\n```\n\ngRPC使用异步io模型：\n\n![](/static/new_blog/4fe9b1ca/2021-12-31/img/grpc_async.png)\n改造一下客户端代码，使用客户端的并行 RPC 调用来计算圆周率。\n```python\n# multithread_client.py\nimport grpc\n\nimport pi_pb2\nimport pi_pb2_grpc\n\nfrom concurrent.futures import ThreadPoolExecutor\n\n\ndef request_2(client):\n\n    def pi(n):\n        return client.Calc(pi_pb2.PiRequest(n=n)).value\n\n    s = time.time()\n    executor = ThreadPoolExecutor(max_workers=4)\n\n    futures = []\n    for i in range(5):\n        future = executor.submit(pi, i)\n        futures.append(future)\n    executor.shutdown(True)\n    print(f\"request 2 cost: {time.time() - s:.3f}\")\n    for future in futures:\n        print(future.result())\n\ndef main():\n    channel = grpc.insecure_channel('localhost:8080')\n    # client 对象是线程安全的\n    client = pi_pb2_grpc.PiCalculatorStub(channel)\n    # 客户端使用线程池执行\n    request_2()\t\n\n\nif __name__ == '__main__':\n    main()\n```\n\n同时可以开启Streaming 模式\n\n![](/static/new_blog/4fe9b1ca/2021-12-31/img/streaming.png)\n协议文件：\n```protobuf\nsyntax = \"proto3\";\n\npackage pi;\n\n// pi service\nservice PiCalculator {\n  // pi method\n  rpc Calc(stream PiRequest) returns (stream PiResponse) {}\n}\n\n// pi input\nmessage PiRequest {\n  int32 n = 1;\n}\n\n// pi output\nmessage PiResponse {\n  int32  n = 1;\n  double value = 2;\n}\n```\nServer:\n```python\ndef Calc(self, request_iterator, ctx):\n  # request 是一个迭代器参数，对应的是一个 stream 请求\n  for request in request_iterator:\n    # 50% 的概率会有响应\n    if random.randint(0, 1) == 1:\n      continue\n\n    s = 0.0\n    for i in range(request.n):\n      s += 1.0 / (2 * i + 1) / (2 * i + 1)\n    # 响应是一个生成器，一个响应对应对应一个请求\n    yield pi_pb2.PiResponse(n=i, value=math.sqrt(8 * s))\n```\nclient:\n```python\ndef generate_request():\n  for i in range(1, 1000):\n    yield pi_pb2.PiRequest(n=i)\n\n    response_iterator = client.Calc(generate_request())\n    for response in response_iterator:\n      print \"pi(%d) =\" % response.n, response.value\n```\n\n处理异常\n```python\ndef Calc(self, request, ctx):\n  if request.n <= 0:\n    ctx.set_code(grpc.StatusCode.INVALID_ARGUMENT)  # 参数错误\n    ctx.set_details(\"request number should be positive\")  # 错误具体说明\n    return pi_pb2.PiResponse()\n  s = 0.0\n  for i in range(request.n):\n    s += 1.0/(2*i+1)/(2*i+1)\n  return pi_pb2.PiResponse(value=math.sqrt(8*s))\n```"}, "2023-02-23/Python -xiang-dui-yin-yong-he-jue-dui-yin-yong--na-ge-geng-hao-": {"title": "Python: 相对引用和绝对引用，哪个更好?", "category": "未分类", "description": "", "date": "2023-02-23", "ref": "", "author": "", "tags": ["Python", "工程化"], "identity": "2023-02-23/Python -xiang-dui-yin-yong-he-jue-dui-yin-yong--na-ge-geng-hao-", "content": "我认为在submodule中使用相对引用是合适的，但在一次提交merge request时，被一个曾任职于Google的权威的工程师拒绝了，原因是：[Google Python Style Guide](https://google.github.io/styleguide/pyguide.html) 禁止使用相对引用：\n> Do not use relative names in imports. Even if the module is in the same package, use the full package name. This helps prevent unintentionally importing a package twice.\n\nPython的两种引用方式，其中相对引用就是以当前代码文件所在位置为参考点，引用其他模块，如：\n```python\nfrom . import xxx\nfrom ...xxx import yyy\n```\n而绝对引用，则是以入口文件或者顶级模块的位置作为参考点，引入其他模块：\n```python\nfrom xxx import yyy\nfrom xxx.yyy import zzz\n```\n有些IDE把这个入口点称为source root，其```__name__```值为```\"__main__\"```。当我们要联合两个git仓库的代码时，要使用绝对引用的方式调用submodule里的python代码，有两种途径：\n* 使main repo和submodule的source root保持一致\n* 在main repo引用submodule之前，加入一句```import sys;sys.path.append({source_root_of_submodule})```\n\n第一种方法很容易理解，Python的引用机制确保了它能够搜索到source root下的模块；而当source root不一致时，会得到一个ModuleNotFoundError，因为import参考点不一样，解释器就找不到模块的正确位置。这意味着，只能把submodule放在main repo的source root下。当submodule一多，main的source root会变得臃肿不堪。更加致命的是，如果submodule的入口点在它的子目录下（很常见，很多仓库最外层是一些licence、document等，代码放在一个叫src的子目录里），在main repo里就无法import它，因为这种代码结构注定了submodule的source root比main repo至少深一个层级。\n\n第二种方式是将submodule的source root加入到main repo的sys.path中。Python解释器在搜索不到模块时，会尝试在sys.path的对应位置查找，所以这种方式看起来是可以work的。但是，```sys.path.append```是一个非常危险的操作！submodule里的包会覆盖sys.path里的同名包，可能会对sys.path造成污染，整个过程都将是悄无声息的。运气不好的话，程序开始启动时能正常运行，但后续会在某个隐藏条件被触发时，突然的产生致命bug。\n\n以上的情形中，使用绝对引用无法避免这些问题。更优雅的解决办法是，submodule里除了main.py、test.py等这些入口文件之外，其他全部使用相对引用。这样main repo可以根据自己的代码结构，灵活地把submodule放在任意位置，此时submodule的source root取决于main的source root，不会再有冲突。\n\n其实不仅仅是google官方的pyguide不建议使用相对引用，诸多大厂的python规范都是如此，Python官方也曾一度要去除相对引用的方式，pep328还介绍了两方阵营的争论过程，但最终相对引用还是得以保留。不用相对引用的原因很多，如pyguide所述\"防止包被引用两次\"，还有它使目录结构不够清晰了然、给人容易出错的感觉等，但不使用绝对引用的理由只有一个，就是在多个代码仓库合并开发时，如果不借助pypi管理包的话，就无法统一参考点。代码规范并非在任何情况下都是金科玉律，在实践中永远要选择合适的方式。\n\n[https://docs.python.org/3.11/tutorial/modules.html#intra-package-references](https://docs.python.org/3.11/tutorial/modules.html#intra-package-references)\n[https://peps.python.org/pep-0328/](https://peps.python.org/pep-0328/)"}, "2023-02-26/MicroPython+rp2040-cao-zuo-IIS-hen-ji-lei": {"title": "MicroPython+rp2040操作IIS，很鸡肋", "category": "硬件", "description": "", "date": "2023-02-26", "ref": "", "author": "", "tags": ["Python", "硬件"], "identity": "2023-02-26/MicroPython+rp2040-cao-zuo-IIS-hen-ji-lei", "content": "## 目录\n\n* [TAS2563](#TAS2563)\n* [RP2040实现IIS](#RP2040-IIS)\n* [时隙太小，很难不间断的传输数据](#time-slot)\n* [总结](#summary)\n\n最近使用tas2563做一个音频相关的项目，想要快速验证方案，就选了用了rp2040作为主控。主要的考量是，rp2040官方加入了MicroPython的支持，在开发上占据一定的便利性。\n\n<h2 id=\"TAS2563\">TAS2563</h2>\n\ntas2563是德州仪器的一款6瓦单声道D类功放，自带DC-DC升压，在2.5v~5.5v电池供电的情况下升至11v，同时有着极高的信噪比和低失真度。它的音频数据接口为TDM，可以配置为标准IIS或者左对齐模式。数据手册中采样率相关的介绍：\n\n![](/static/new_blog/4fe9b1ca/2023-02-26/i2s.png)\n\n> The TDM serial audio port supports up to 16 32-bit time slots at 44.1/48 kHz, 8 32-bit time slots at a 88.2/96 kHz sample rate and 4 32-bit time slots at a 176.4/192 kHz sample rate. The device supports 2 time slots at 32 bits in width and 4 or 8 time slots at 16, 24 or 32 bits in width. Valid SBCLK to FSYNC ratios are 64, 96, 128, 192, 256, 384 and 512. The device will automatically detect the number of time slots and this does not need to be programmed.\n\n其中规定了SBCLK和FSYNC最低的时钟比是64，即每一帧数据至少要达到64bit，哪怕传输24bit（双声道48bit，后同理）、16bit甚至是8bit音频，也要在末尾添补0来凑齐64个时钟。这其实是个缺点，因为它强行拉高了SBCLK的时钟频率，进而也拉高了主控的时钟。\n\ntas2563的采样率最高支持96kHz，但过高的时钟频率对主控投喂数据的实效要求更高。通常认为44.1kHz的采样率已经有足够的声音表现。鉴于其总线要求，在这个采样率下，SBCLK的频率为2.8224Mhz，如果传输16bit音频，码率为1378 kbps，约172.3 KB/s。\n\n<h2 id=\"RP2040-IIS\">RP2040实现IIS</h2>\n\nrp2040没有IIS外设接口，但有两个PIO块，每个PIO块有4个状态机，共享32个槽位的指令缓存。实现一个IIS接口，使用1个状态机就够了。由于每条指令占用一个状态机时钟，可以画出标准32bit IIS时序图：\n![](/static/new_blog/4fe9b1ca/2023-02-26/ana.jpg)\n对应的程序如下：\n```python\n@asm_pio(out_init=PIO.OUT_LOW, sideset_init=(PIO.OUT_HIGH, PIO.OUT_HIGH), pull_thresh=32, autopull=True, fifo_join=PIO.JOIN_TX,)\ndef Audio_PIO():\n    # SBCLK active: rising edge\n    #                              _ FSYNC\n    #                             / _ SBCLK\n    #                             |/\n    set(x, 15)            .side(0b11)\n    label(\"high_ch\")\n    out(pins, 1)          .side(0b10)\n    jmp(x_dec,\"high_ch\")  .side(0b11)\n\n    set(x, 13)            .side(0b10)\n    label(\"high_nop\")\n    nop()                 .side(0b11)\n    jmp(x_dec,\"high_nop\") .side(0b10)\n    nop()                 .side(0b11)\n    nop()                 .side(0b00)\n\n    set(x, 15)            .side(0b01)\n    label(\"low_ch\")\n    out(pins, 1)          .side(0b00)\n    jmp(x_dec,\"low_ch\")   .side(0b01)\n\n    set(x, 13)            .side(0b00)\n    label(\"low_nop\")\n    nop()                 .side(0b01)\n    jmp(x_dec,\"low_nop\")  .side(0b00)\n    nop()                 .side(0b01)\n    nop()                 .side(0b10)\n```\n\n在主循环中，往状态机中的tx FIFO写入数据0xAAAA_5555，左右声道各16bit ，从逻辑分析仪可以看到标准信号：\n![](/static/new_blog/4fe9b1ca/2023-02-26/rp2040_iis.png)\n\n实现了这一步，已经可以让tas2563发出声音了。但如果要让它播放歌曲，才是最困难的一步。如果所有音频都存储于ROM，那直接读取就好，几乎没有任何障碍。但这是不现实的，rp2040最大仅支持16MB的ROM，如果以wav格式存储44.1kHz 16bit音频，最多也只能存90秒。所以借助外部存储是有必要的。\n\n这可以借助SD卡，从MicroPython官方文档中ESP32的章节里，可以获取一个使用SPI总线操作SD卡的实例。可以无修改的移植到rp2040上，并挂载到文件系统中：\n```python\nimport os\nfrom machine import SPI, Pin\nfrom lib import SDCard  # 移植来的SD卡操作库\n\nsd = SDCard(spi=SPI(0, baudrate=60_000_000, sck=Pin(18), mosi=Pin(19), miso=Pin(16)), cs=Pin(17))\nos.mount(sd, '/sd')\n```\n这样一来，貌似可以在主程序中从sd卡读取文件，写入到状态机的tx FIFO里就可以播放音乐。但它还是有一个致命问题。\n\n<h2 id=\"time-slot\">时隙太小，很难不间断的传输数据</h2>\n\n在44.1 kHz的采样率下，每帧的时间间隔为22.6 us，IIS是一个 __时钟严格__ 的同步总线，如果下一帧数据没有在这个时隙中准备好，就会听到失真的声音甚至爆音。将状态机的rx FIFO和tx FIFO合并，得到8个32bit的FIFO，也仅有180多us，这个时隙太短了。\n\n读SD卡的延迟太高了，远远超过了180多us。这里特别强调是延迟，因为它的带宽还可以，不是真正的阻碍。即使采用spi总线，连续读的带宽也可轻松达到1MB/s，用来驱动这个IIS足够了。最大的还是延迟的问题，假如打开一个文件并读几个字节，等待时间有时高达数毫秒，这里有一部分是MicroPython和FatFS的损耗，还有一部分是不可控的gc。同步读、同步写很难不卡的，只能借助一个更大的buffer实现异步操作。\n\n在只有264KB RAM的rp2040上，开辟一个20KB的array几乎是极限了，再大的话可能因为找不到这么大的连续内存空间而产生MemoryError，这是MicroPython的限制。在这个条件下，也只能勉强得到115毫秒的时间窗口用来准备数据。假设这个时间窗是足够的，有两种方式借助这个buffer把数据从SD卡传输到状态机里：\n* 在循环里一直读取数据，设置一个时隙稍小于180us周期性定时中断，在中断里把状态机的FIFO空间填满\n* rp2040是双核的，在一个核心里取数据，另一个核心写数据到状态机\n\n第一种方式，除非自己用C写扩展，否则无法实现。MicroPython官方的定时器，最小只能设置1ms的定时周期，已经大大超过了180us。即使如此，每次进入中断和离开中断，都有很大的性能损耗，这主要是mPy运行时和上下文切换的开销。\n\n而对于第二种方式，在两个核间共享数据，需要实现互斥锁。rp2040没有半传输中断机制，需要自己实现，在写buffer的core里不停轮训一个变量，以得知另一个core读取到buffer的哪个位置。这可能需要精细的控制时序，并且使用 [Maximising MicroPython speed](https://docs.micropython.org/en/latest/reference/speed_python.html) 技巧实现加速。但经过反复调试，还是很难保证每个180us时隙内都能取到有效数据，因为等待锁的时间是不可预知的，借助mPy文件系统读取sd卡过程中会申请内存、释放对象（即使使用了readinto到一个预申请的buff中，代替read），以及随机的gc，这些偶然因素都会造成抖动。用逻辑分析仪观察，它会偶尔出现一些空隙，造成爆音：\n![](/static/new_blog/4fe9b1ca/2023-02-26/bad_bus.png)\n\n\n<h2 id=\"summary\">总结</h2>\n\nMicroPython还是比较鸡肋。本来它和嵌入式应用场景就有些相悖，在264KB RAM的rp2040，光mPy运行时就占用了80多KB的RAM。各个模块的API也十分简略，比如ADC，它只能支持简单的单次转换，没有任何高阶功能。为了降低入门门槛、提高编程便捷性，在寸土寸金的硬件资源上，耗费了巨量的资源却只能实现很简略的功能，这个取舍到底是否值得，有待探讨。"}, "2023-02-28/Kubeflow Pipeline-jian-jie": {"title": "Kubeflow Pipeline简介", "category": "kubeflow", "description": "", "date": "2023-02-28", "ref": "", "author": "", "tags": [], "identity": "2023-02-28/Kubeflow Pipeline-jian-jie", "content": "KubelowPipelines（KFP）是一个通过使用Docker容器构建和部署可移植和可扩展机器学习（ML）工作流的平台，KFP可作为Kubelow的核心组件，也可以独立安装。KFL要达成的目标是:\n* 工作流 end-to-end 的编排\n* 组件和 pipeline 可重用、灵活组合\n* 易于管理和追踪，对 pipeline的定义、运行、experiments和ML artifacts进行可视化\n* 通过缓存消除重复的执行来提升计算资源的利用率\n* 通过平台无关的 IR YAML pipeline 定义达成跨平台流水线可移植性\n\npipeline即流水线，是一种工作流的定义，它将一个或多个组件组合在一起，形成计算有向无环图（DAG）。在运行时，每个组件执行都对应于单个容器执行，这可能会创建ML artifacts。管道也可能具有控制流的功能。\n\n## 安装\n\n参考链接[https://www.kubeflow.org/docs/components/pipelines/v2/installation/](https://www.kubeflow.org/docs/components/pipelines/v2/installation/)\n\n\n## 组件\n\n组件是组成KFP的组成部分，它定义输入，在body中具有用户自定义的逻辑，并生成output。当一个组件模板实例化后，被称为任务（task）.KFP提供了两种编写组件的高级方法：Python组件和容器组件。\n* Python Components: 用纯Python编写组件的便捷方法，此时又有两种类型：\n  * 轻量级Python组件\n  * 容器化Python组件\n\n* 容器组件: 可以使用任意容器定义来定义组件，从而提供了一种更灵活、更高级的创作方法\n\n__Importer Components__ 是KFP提供的一种特殊的“pre-baked”组件，允许你引入一个外部生成的artifact到pipeline中。\n\n在kubeflow整体架构中，下面两张图列出了在测试阶段和生产阶段pipeline所处的位置和作用：\n![](/static/new_blog/4fe9b1ca/2023-02-28/ex.png)\n![](/static/new_blog/4fe9b1ca/2023-02-28/prod.png)\n\n## 简单实践\n\n首先，需要通过pip命令安装kfp：`pip install kfp --pre`，然后写一个hello world pipeline：\n```python\nfrom kfp import dsl\n\n@dsl.component\ndef say_hello(name: str) -> str:\n  hello_text = f'Hello, {name}!'\n  print(hello_text)\n  return hello_text\n\n@dsl.pipeline\ndef hello_pipeline(recipient: str) -> str:\n  hello_task = say_hello(name=recipient)\n  return hello_task.output\n```\n可以使用`KFP SDK DSL Compiler`将pipeline编译成YAML：\n```python\nfrom kfp import compiler\n\ncompiler.Compiler().compile(hello_pipeline, 'pipeline.yaml')\n```\n执行完这一步，可以看到当前路径下的pipeline文件：\n```yaml\ncomponents:\n  comp-say-hello:\n    executorLabel: exec-say-hello\n    inputDefinitions:\n      parameters:\n        name:\n          parameterType: STRING\n    outputDefinitions:\n      parameters:\n        Output:\n          parameterType: STRING\ndeploymentSpec:\n  executors:\n    exec-say-hello:\n      container:\n        args:\n        - --executor_input\n        # ...\n```\n`dsl.component`和`dsl.pipeline`装饰器分别将下述带类型注解的python函数 转化成KFP component和pipeline，`KFP SDK compiler`将域特定语言（DSL）对象编译为一个hermetic pipeline YAML文件， 此时将其提交到`KFP-conformant`后端来执行，如果此前已经部署了一个KFP开源后端实例并且获得了部署的endpoint，则可以直接通过`KFP SDK Client`直接提交执行，以下内容以参数`recipient='World'`提交管道执行：\n```python\nfrom kfp.client import Client\n\nclient = Client(host='<MY-KFP-ENDPOINT>')\nrun = client.create_run_from_pipeline_package(\n    'pipeline.yaml',\n    arguments={\n        'recipient': 'World',\n    },\n)\n```\n客户端将打印出一个链接用于在UI中观察pipeline的执行图和日志，在这个例程它只有1个task打印和返回`Hello, World!`。"}, "2023-03-14/-xiu-gai-nginx-yuan-ma-yi-shan-chu-huo-zi-ding-yi- Server Header": {"title": "修改nginx源码以删除或自定义 \"Server\" Header", "category": "web", "description": "", "date": "2023-03-14", "ref": "", "author": "", "tags": ["nginx", "web"], "identity": "2023-03-14/-xiu-gai-nginx-yuan-ma-yi-shan-chu-huo-zi-ding-yi- Server Header", "content": "边缘计算等对内存极其敏感的场景下，在进行HTTP通信时往往需要移除一些不必要内容以节约内存。使用nginx正向代理时，它会添加默认的Server Header，即使在nginx.conf中指定了```server_tokens off;```，也仅仅是隐藏版本号，并未去除这个Header。\n\n## 隐藏Header\n\n这部分的逻辑在 ```src/http/ngx_http_header_filter_module.c``` 中定义:\n```C\n...\nstatic u_char ngx_http_server_string[] = \"Server: nginx\" CRLF;\nstatic u_char ngx_http_server_full_string[] = \"Server: \" NGINX_VER CRLF;\nstatic u_char ngx_http_server_build_string[] = \"Server: \" NGINX_VER_BUILD CRLF;\n...\n\nstatic ngx_int_t\nngx_http_header_filter(ngx_http_request_t *r)\n{\n   ...\n    if (r->headers_out.server == NULL) {\n        if (clcf->server_tokens == NGX_HTTP_SERVER_TOKENS_ON) {\n            len += sizeof(ngx_http_server_full_string) - 1;\n\n        } else if (clcf->server_tokens == NGX_HTTP_SERVER_TOKENS_BUILD) {\n            len += sizeof(ngx_http_server_build_string) - 1;\n\n        } else {\n            len += sizeof(ngx_http_server_string) - 1;\n        }\n    }\n    ...\n    b = ngx_create_temp_buf(r->pool, len);\n    ...\n    if (r->headers_out.server == NULL) {\n        if (clcf->server_tokens == NGX_HTTP_SERVER_TOKENS_ON) {\n            p = ngx_http_server_full_string;\n            len = sizeof(ngx_http_server_full_string) - 1;\n\n        } else if (clcf->server_tokens == NGX_HTTP_SERVER_TOKENS_BUILD) {\n            p = ngx_http_server_build_string;\n            len = sizeof(ngx_http_server_build_string) - 1;\n\n        } else {\n            p = ngx_http_server_string;\n            len = sizeof(ngx_http_server_string) - 1;\n        }\n\n        b->last = ngx_cpymem(b->last, p, len);\n    }\n```\n可以得知，在处理header时，nginx先计算header部分的内存大小，再申请一块buffer，然后进行填充，所以对```headers_out.server```进行了两次判断。可以对上述两个if判断块进行注释，这样在请求时就不会有server字段：\n```shell\n~/nginx # curl -I localhost/\n\nHTTP/1.1 200 OK\nDate: Wed, 15 Mar 2023 03:10:25 GMT\nContent-Type: text/html\nContent-Length: 615\nLast-Modified: Wed, 15 Mar 2023 02:55:32 GMT\nConnection: keep-alive\nETag: \"641133a4-267\"\nAccept-Ranges: bytes\n```\n\n## 使其可配置\n\n在```ngx_http_header_filter```可以看到```clcf```结构体，类型为```ngx_http_core_loc_conf_t```，其为conf文件中http部分配置的解析逻辑：\n```C\nstruct ngx_http_core_loc_conf_s {\n    ngx_str_t     name;          /* location name */\n    ngx_str_t     escaped_name;\n\n#if (NGX_PCRE)\n    ngx_http_regex_t  *regex;\n#endif\n    ...\n    ngx_http_location_tree_node_t   *static_locations;\n#if (NGX_PCRE)\n    ngx_http_core_loc_conf_t       **regex_locations;\n#endif\n    ...\n```\n实现自定义server name，可以把配置添加到这个块当中:\n```C\n    // add\n    ngx_str_t     customized_server_name;\n```\n同时要处理解析配置文件的地方，nginx从这里加载配置，并等待event，在event handler当中根据addr：port等参数寻找server的配置，并组装成request对象。conf文件解析的主要逻辑在```ngx_conf_handler```等函数当中，这里遍历每个ngx_command数组，每个元素对应一条解析项，配置的解析根据其属性进行对应的处理：\n```C\nstruct ngx_command_s {\n    ngx_str_t             name;\n    ngx_uint_t            type;\n    char               *(*set)(ngx_conf_t *cf, ngx_command_t *cmd, void *conf);\n    ngx_uint_t            conf;\n    ngx_uint_t            offset;\n    void                 *post;\n};\n```\n其中，其中，`name`是配置项名称，`type`决定这个配置项可以在哪些块，nginx使用位标记来标识，`set`则为设置配置的回调方法。`conf`用于指示配置项所处内存的相对偏移位置，`offset`表示当前配置项在整个存储配置项的结构体中的偏移位置。由此，可以在```src/http/ngx_http_core_module.c```中定义自定义的command：\n```C\nstatic ngx_command_t  ngx_http_core_commands[] = {\n    ...\n    \n    // add\n    { ngx_string(\"customized_server_name\"),\n      NGX_HTTP_MAIN_CONF|NGX_CONF_TAKE1,\n      ngx_conf_set_str_slot,\n      NGX_HTTP_LOC_CONF_OFFSET,\n      offsetof(ngx_http_core_loc_conf_t, customized_server_name),\n      NULL },\n    ...\n    ngx_null_command\n}\n```\n其中`ngx_conf_set_str_slot`是nginx预置的回调函数。若在多个域同时出现配置项时，nginx需要根据某些优先规则确定使用那个配置，nginx实现了一个merge机制来处理这个逻辑，对于没有merge函数的配置，最终不会生效。http域的merge定义在此文件```ngx_http_core_merge_loc_conf```函数中，在这里优先取子层存在的配置，若无则取上层的，否则取默认。可以添加上自定义配置项的merge函数：\n```C\nstatic char *\nngx_http_core_merge_loc_conf(ngx_conf_t *cf, void *parent, void *child)\n{\n    ngx_http_core_loc_conf_t *prev = parent;\n    ngx_http_core_loc_conf_t *conf = child;\n    ...\n    // add\n    ngx_conf_merge_str_value(conf->customized_server_name,\n                             prev->customized_server_name, \"undefined\");\n    ...\n}\n```\n这样一来，就可以在`ngx_http_header_filter`当中获取到此配置项，修改这两处的逻辑：\n```C\nstatic ngx_int_t\nngx_http_header_filter(ngx_http_request_t *r)\n{\n    ...\n    // modify\n    if (r->headers_out.server == NULL) {\n        if (clcf->server_tokens == NGX_HTTP_SERVER_TOKENS_ON) {\n            len += sizeof(\"Server: \") - 1 + clcf->customized_server_name.len + 2;\n        }\n    }\n    ...\n    b = ngx_create_temp_buf(r->pool, len);\n    ...\n    \n    // modify\n    if (r->headers_out.server == NULL) {\n        if (clcf->server_tokens == NGX_HTTP_SERVER_TOKENS_ON) {\n            p = clcf->customized_server_name.data;\n            len = clcf->customized_server_name.len;\n\n            b->last = ngx_cpymem(b->last, \"Server: \", sizeof(\"Server: \") - 1);\n            b->last = ngx_cpymem(b->last, p, len);\n            *b->last++ = CR; *b->last++ = LF;\n        }\n    }\n    ...\n```\n需要注意```len += sizeof(\"Server: \") - 1 + clcf->customized_server_name.len + 2;```计算长度时，sizeof会包含字符串结尾的`\\0`，拷贝到buffer的内容不包含这部分，故需减一。每条Header结束的`\\r\\n`占用2字节，故在末尾加2。\n\n编译运行，并在`nginx.conf`中添加：\n```\n...\nhttp {\n    customized_server_name jjcjj;\n    \n    include       mime.types;\n    default_type  application/octet-stream;\n    ...\n```\n启动后，可以看到自定义的Server已经生效：\n```shell\n~/nginx # curl -I localhost/\n\nHTTP/1.1 200 OK\nServer: jjcjj\nDate: Wed, 15 Mar 2023 03:10:25 GMT\nContent-Type: text/html\nContent-Length: 615\nLast-Modified: Wed, 15 Mar 2023 02:55:32 GMT\nConnection: keep-alive\nETag: \"641133a4-267\"\nAccept-Ranges: bytes\n```\n当未指定`customized_server_name`时，Server会返回默认值`undefined`；添加`server_tokens off`则不会返回Server Header，效果同上文所述。"}}, "tag_map": {"protobuf": ["2021-12-31/-shi-yong-RPC-gou-jian-gao-bing-fa-web-ying-yong"], "web": ["2023-03-14/-xiu-gai-nginx-yuan-ma-yi-shan-chu-huo-zi-ding-yi- Server Header", "2021-12-31/-shi-yong-RPC-gou-jian-gao-bing-fa-web-ying-yong"], "rpc": ["2021-12-31/-shi-yong-RPC-gou-jian-gao-bing-fa-web-ying-yong"], "Python": ["2023-02-26/MicroPython+rp2040-cao-zuo-IIS-hen-ji-lei", "2023-02-23/Python -xiang-dui-yin-yong-he-jue-dui-yin-yong--na-ge-geng-hao-"], "工程化": ["2023-02-23/Python -xiang-dui-yin-yong-he-jue-dui-yin-yong--na-ge-geng-hao-"], "硬件": ["2023-02-26/MicroPython+rp2040-cao-zuo-IIS-hen-ji-lei"], "nginx": ["2023-03-14/-xiu-gai-nginx-yuan-ma-yi-shan-chu-huo-zi-ding-yi- Server Header"]}, "category_map": {"web": ["2023-03-14/-xiu-gai-nginx-yuan-ma-yi-shan-chu-huo-zi-ding-yi- Server Header", "2021-12-31/-shi-yong-RPC-gou-jian-gao-bing-fa-web-ying-yong"], "未分类": ["2023-02-23/Python -xiang-dui-yin-yong-he-jue-dui-yin-yong--na-ge-geng-hao-"], "硬件": ["2023-02-26/MicroPython+rp2040-cao-zuo-IIS-hen-ji-lei"], "kubeflow": ["2023-02-28/Kubeflow Pipeline-jian-jie"]}}